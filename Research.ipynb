{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90b47805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from typing import List\n",
    "import langchain\n",
    "from langchain_core.documents import Document\n",
    "from pinecone import Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chat_models.base import init_chat_model\n",
    "from langchain.chains import create_history_aware_retriever\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b81e25c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to load each excel file as a separate document\n",
    "def load_Excel(file_path:str)-> List[Document]:\n",
    "    document=[]\n",
    "    excelfile=pd.ExcelFile(file_path)\n",
    "    for sheet_name in excelfile.sheet_names:\n",
    "        df=pd.read_excel(file_path,sheet_name=sheet_name)\n",
    "\n",
    "        sheet_content=f\"Sheet Name: {sheet_name} \\n\"\n",
    "        sheet_content+=f\"Column Name: {' ,'.join(df.columns)} \\n\"\n",
    "        sheet_content+=f\"Number of Records: {len(df)} \\n\"\n",
    "        sheet_content+=df.to_string(index=False)\n",
    "        doc=Document(page_content=sheet_content,metadata={\"Data Source\":\"Excel File\",\"Source\":file_path,\"Number of Records\":len(df)\n",
    "                                                          ,\"Number of Columns\":len(df.columns),\"Month\":sheet_name\n",
    "                                                          })\n",
    "        document.append(doc)\n",
    "    return document\n",
    "        \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "48aa7dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the excel file to create list of documents\n",
    "documents=load_Excel(\"/Users/aswinganapathysubramanian/Documents/PersonalProjects/Test/Finance.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4ef28df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the OpenAI and Pinecone api keys in the environment (Note add the api keys in the .env file)\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"]=os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"PINECONE_API_KEY\"]=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aadaee21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing Embedding, we are using openai embedding\n",
    "embeddings=OpenAIEmbeddings(model=\"text-embedding-3-small\", dimensions=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db117cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the documents into chunks\n",
    "#Initializing the text splitter\n",
    "text_splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    "    separators=[\" \",\"\\n\"]\n",
    ")\n",
    "\n",
    "chunks=text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b006c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing  the instance for the Vector Database\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")\n",
    "pc=Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "73793918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if the index is already present\n",
    "index_name=\"personalfinance\"\n",
    "\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1024,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30ef27d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accessing the index\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5be9a417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the Vector Store\n",
    "vector_store=PineconeVectorStore(index=index,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ee3b10d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bffeb65b-4fbd-4edf-b0fd-0842924e486d',\n",
       " '7e4a4f36-16ca-4489-bc21-584fd6afada1',\n",
       " '6173602d-c6d1-422c-b0ba-18e53a5b177e',\n",
       " 'd3443686-dff3-46d5-97a9-4905b794187c',\n",
       " '827e74d0-ebdc-4113-a193-2e25c899c2dc',\n",
       " '12ff00ba-c8c5-4de4-b8f6-617b215533a1',\n",
       " '83e85d57-2d64-4d27-bbf0-6727149a99f0',\n",
       " '4c74e152-9037-4c99-b945-9e1270b44273',\n",
       " '6beb556b-6321-487e-b04f-f1bfe4ebbeef',\n",
       " '3908fc65-8db5-482c-a1e7-4746067200e9',\n",
       " '65010404-4824-4448-bf92-c1eb86d088c2',\n",
       " '55c3ea14-a73d-40e2-8898-e3ad64780b4f']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding the chunks to the vector store\n",
    "vector_store.add_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9becdfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the vector store as retriever\n",
    "retriever= vector_store.as_retriever(search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27c722c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['PineconeVectorStore', 'OpenAIEmbeddings'], vectorstore=<langchain_pinecone.vectorstores.PineconeVectorStore object at 0x120da1450>, search_kwargs={'k': 3})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4796737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm=ChatOpenAI(model=\"gpt-5.2\",temperature=0.2, max_completion_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "24d92aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt that includes the chat history\n",
    "contextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \n",
    "which might reference context in the chat history, formulate a standalone question \n",
    "which can be understood without the chat history. Do NOT answer the question, \n",
    "just reformulate it if needed and otherwise return it as is.\"\"\"\n",
    "\n",
    "contextualize_q_prompt= ChatPromptTemplate.from_messages([\n",
    "    (\"system\", contextualize_q_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\",\"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d65482e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a history aware retriever\n",
    "history_aware_retriever=create_history_aware_retriever(llm,retriever, contextualize_q_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d809e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new document chain with history\n",
    "qa_system_prompt=\"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "qa_prompt=ChatPromptTemplate.from_messages([\n",
    "    (\"system\",qa_system_prompt),\n",
    "    MessagesPlaceholder(\"chat_history\"),\n",
    "    (\"human\",\"{input}\")\n",
    "])\n",
    "\n",
    "question_answer_chain=create_stuff_documents_chain(llm,qa_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c361ab68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Conversation_Rag_chain=create_retrieval_chain(history_aware_retriever,\n",
    "                                              question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7085dd49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is my major spending for January\n",
      "A: In January, the largest single expense is **Furniture (Ikea)** for **$686.13** (Harini, 2025-01-25). The next biggest major spend is **Car EMI**: **$590.00** (Aswin, 2025-01-16) and **$522.52** (Harini, 2025-01-16).\n"
     ]
    }
   ],
   "source": [
    "#Invoking conversational Retriever\n",
    "chat_history=[]\n",
    "result1= Conversation_Rag_chain.invoke({\n",
    "    \"chat_history\":chat_history,\n",
    "    \"input\": \"What is my major spending for January\"\n",
    "})\n",
    "\n",
    "print(f\"Q: What is my major spending for January\")\n",
    "print(f\"A: {result1['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "06e1e9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history.extend([\n",
    "    HumanMessage(content=\"What is my major spending for January\"),\n",
    "    AIMessage(content=result1['answer'])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4130eb59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: WHo spent the most in January?\n",
      "A: **Harini** spent the most in January: **$1,997.24** total vs **Aswin** at **$1,634.21**.\n"
     ]
    }
   ],
   "source": [
    "##Follow Up question\n",
    "result2= Conversation_Rag_chain.invoke({\n",
    "    \"chat_history\":chat_history,\n",
    "    \"input\": \"WHich person spent the most in January based on data provided?\" #Refers to ML from Previous Question\n",
    "})\n",
    "\n",
    "print(f\"Q: WHo spent the most in January?\")\n",
    "print(f\"A: {result2['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aec7d63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0253e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Test (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
